{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18900 entries, 0 to 18899\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  18880 non-null  object\n",
      " 1   type      18900 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 295.4+ KB\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_23 (Embedding)     (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "95/95 [==============================] - 19s 181ms/step - loss: 0.1430 - recall_22: 0.9838 - val_loss: 0.0625 - val_recall_22: 0.9758\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f1d98ddbced0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from keras.metrics import Recall\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "df= pd.read_csv(\"./dataset/myDataset/myDataset.csv\", encoding='utf-16')\n",
    "df.head()\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.dropna(inplace=True)#to drop out nan values\n",
    "\n",
    "X=df['sentence']\n",
    "y=df['type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = RNN()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=[Recall()])\n",
    "\n",
    "history2 = model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "\n",
    "\n",
    "validation_loss = history2.history['val_loss']\n",
    "training_loss = history2.history['loss']\n",
    "\n",
    "epoch_count = range(1, len(validation_loss) + 1)\n",
    "print('Epoch Count' , epoch_count)\n",
    "print('Validation Loss:' , validation_loss)\n",
    "fig=plt.figure(figsize = (12, 4))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "plt.plot(epoch_count, validation_loss, 'm-')\n",
    "plt.plot(epoch_count, training_loss, 'b-')\n",
    "plt.legend(['Humbjet e validimit', 'Humbjet e trajnimit'])\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Humbja')\n",
    "\n",
    "# history2 = model.fit(sequences_matrix,y_train,batch_size=128,epochs=epochs,\n",
    "#           validation_split=0.2,callbacks=[EarlyStopping(monitor='val_accuracy',min_delta=0.0001)])\n",
    "\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# training_acc = history.history['accuracy']\n",
    "\n",
    "# epoch_count = range(1, len(val_acc) + 1)\n",
    "\n",
    "# fig.add_subplot(122)\n",
    "# plt.plot(epoch_count, val_acc, 'm-')\n",
    "# plt.plot(epoch_count, training_acc, 'b-')\n",
    "# plt.legend(['Saktësia e validimit', 'Saktësia e trajnimit'])\n",
    "# plt.xlabel('Epoka')\n",
    "# plt.ylabel('Saktësia')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Numri i epokave {}.\".format(epochs))\n",
    "# print(\"Mesatarja e saktësisë nëpër epoka {:.2f}%\".format(statistics.mean(val_acc)*100))\n",
    "# print(\"Minimumi i saktësisë nëpër epoka {:.2f}%\".format(min(val_acc)*100))\n",
    "# print(\"Maksimumi i saktësië nëpër epoka {:.2f}%\".format(max(val_acc)*100))\n",
    "\n",
    "\n",
    "X_test_sequences = tok.texts_to_sequences(X_test)\n",
    "X_test_sequences_matrix = sequence.pad_sequences(X_test_sequences,maxlen=max_len)\n",
    "\n",
    "recall = model.evaluate(X_test_sequences_matrix,y_test)\n",
    "\n",
    "print('Test set\\n Loss: {:0.3f}\\n Recall: {:0.3f}'.format(recall[0],recall[1]))\n",
    "\n",
    "y_pred=model.predict(X_test_sequences_matrix)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>0.5:\n",
    "        y_pred[i]=1\n",
    "    elif y_pred[i]<=0.5:\n",
    "        y_pred[i]=0\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# m = confusion_matrix(y_test, y_pred)\n",
    "# plot_confusion_matrix(history, X_test, y_test)  \n",
    "# plt.show()\n",
    "\n",
    "accuracy= accuracy_score(y_test, y_pred)\n",
    "precision= precision_score(y_test, y_pred, zero_division=1)\n",
    "recall= recall_score(y_test, y_pred, zero_division=1)\n",
    "print(\" Accuracy : {0} \\n Precision : {1} \\n Recall : {2}\".format(accuracy, precision, recall))\n",
    "\n",
    "from keras.models import load_model\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model.save_weights(\"lstm_weights.h5\")\n",
    "print('done')\n",
    "\n",
    "model.save('lstm_model.h5')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('lstm_model.h5')\n",
    "loaded_model.load_weights('lstm_weights.h5')  \n",
    "\n",
    "def clean_data(input_val):\n",
    "\n",
    "    txts = tok.texts_to_sequences(input_val)\n",
    "    input_val = sequence.pad_sequences(txts, maxlen=max_len)\n",
    "\n",
    "    return input_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
